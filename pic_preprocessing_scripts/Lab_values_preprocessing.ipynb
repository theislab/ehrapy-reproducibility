{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b41de05f-4183-4022-9d4a-5046521869db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfb32311-e335-4c1e-bcd9-be42bc6137c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_labitem_df = pd.read_csv(\"../V1.1.0/D_LABITEMS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52083209-b1ca-4777-92c5-186362e5dfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "icu_stay_df = pd.read_csv(\"./temp_pp_data_files/icu_stay_mibi_NEW.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c5e08e4-3f11-4dcd-ae9a-9d6a68059cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_events_df = pd.read_csv(\"../V1.1.0/LABEVENTS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c64f289-796e-4f1e-8d14-4ba2196a1574",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lab_grp_by_hadm = lab_events_df.groupby(\"ITEMID\")[\"HADM_ID\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4d656cd-15f7-4076-a0dd-5b69aa92bba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# side note: there are 13449 different HADMs in the dataset\n",
    "# so check how many values had at least one measurement relative to all HADMs\n",
    "most_common_values = lab_grp_by_hadm.loc[(lab_grp_by_hadm / 13449) > 0.90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecd90584-356c-47c6-91c8-7554756da000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# which values are common?\n",
    "d_labitem_df = pd.read_csv(\"../V1.1.0/D_LABITEMS.csv\")\n",
    "# change here to add new lab values, 5241 -> a02/fi02 -> like 0% values\n",
    "idx_lst = [5241]  # most_common_values.index.to_list()\n",
    "id_to_name_grp = d_labitem_df.query(\"ITEMID in @idx_lst\").groupby(\"ITEMID\")[\"LABEL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e34b2d91-7ee3-4a4f-af3b-aaee2b616dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map name to item_id; this is possible as one item_id always defines one single value and not multiples\n",
    "id_to_name = id_to_name_grp.apply(\n",
    "    lambda grp: list(grp.value_counts().index)[0]\n",
    ").to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7498828-16cd-4593-9280-5640bff1e68e",
   "metadata": {},
   "source": [
    "# Preprocess lab values outliers\n",
    "\n",
    "To reduce the effect and influence of extreme outliers and include them into calculation (for example average), winsorize the lab values in the original data and use them for downstream analysis.\n",
    "\n",
    "1.) Calculate the upper and lower fence per column that is: 75%/25% quantile three times their difference +/-; --> all values otuside those fences are probably errors and not extreme outliers.\n",
    "\n",
    "\n",
    "2.) Per upper/lower fence per column: Determine the quantile, that is closest to the respective fence (in 2.5% steps). This is typically around 95% for upper and about 5% for lower fence.\n",
    "\n",
    "3.) Set all values above/below to that quantiles value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95d3120a-af73-41a2-8c92-5af6649e20a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_value_item_ids = list(id_to_name.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09e77ccf-bdd7-408e-9d18-a8b1bd291baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc upper outer fence: turkeys method boxplot (marks border between possible and actual outliers)\n",
    "# --> useful for winsorizing\n",
    "def uo_fence(df):\n",
    "    q1 = df[\"VALUENUM\"].quantile(0.25)\n",
    "    q3 = df[\"VALUENUM\"].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    outer_fence = 3 * iqr\n",
    "    outer_fence_le = q1 - outer_fence\n",
    "    outer_fence_ue = q3 + outer_fence\n",
    "    return outer_fence_ue, outer_fence_le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd9ef7af-4d36-4956-8a32-e3ef287b7ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate upper and lower fence per column\n",
    "upper_fences = {}\n",
    "lower_fences = {}\n",
    "for lab_val_id in lab_value_item_ids:\n",
    "    lab_val_only_df_mask = lab_events_df[\"ITEMID\"] == lab_val_id\n",
    "    fence_up, fence_low = uo_fence(lab_events_df.loc[lab_val_only_df_mask])\n",
    "    fence_up, fence_low = round(fence_up, 2), round(fence_low, 2)\n",
    "    upper_fences[lab_val_id] = fence_up\n",
    "    lower_fences[lab_val_id] = fence_low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57c28003-433e-4a7a-bf53-eaf0f1fee1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate closest upper quantile for upper fence\n",
    "k_dict_up = {}\n",
    "for lab_val_id in upper_fences:\n",
    "    lab_val_only_df_mask = lab_events_df[\"ITEMID\"] == lab_val_id\n",
    "    vals_only_df = lab_events_df.loc[lab_val_only_df_mask]\n",
    "    quant_90 = vals_only_df[\"VALUENUM\"].quantile(0.90)\n",
    "    quant_925 = vals_only_df[\"VALUENUM\"].quantile(0.925)\n",
    "    quant_95 = vals_only_df[\"VALUENUM\"].quantile(0.95)\n",
    "    quant_975 = vals_only_df[\"VALUENUM\"].quantile(0.975)\n",
    "    quant_99 = vals_only_df[\"VALUENUM\"].quantile(0.99)\n",
    "    tmp_lst = [quant_90, quant_925, quant_95, quant_975, quant_99]\n",
    "    closest_idx = (np.abs(tmp_lst - upper_fences[lab_val_id])).argmin()\n",
    "    k_dict_up[lab_val_id] = round(tmp_lst[closest_idx], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2e37a48-9584-4fe6-bfa5-761f55327559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate closest lower quantile for lower fence\n",
    "k_dict_low = {}\n",
    "for lab_val_id in lower_fences:\n",
    "    lab_val_only_df_mask = lab_events_df[\"ITEMID\"] == lab_val_id\n",
    "    vals_only_df = lab_events_df.loc[lab_val_only_df_mask]\n",
    "    quant_10 = vals_only_df[\"VALUENUM\"].quantile(0.10)\n",
    "    quant_075 = vals_only_df[\"VALUENUM\"].quantile(0.075)\n",
    "    quant_05 = vals_only_df[\"VALUENUM\"].quantile(0.05)\n",
    "    quant_025 = vals_only_df[\"VALUENUM\"].quantile(0.025)\n",
    "    quant_01 = vals_only_df[\"VALUENUM\"].quantile(0.01)\n",
    "    tmp_lst = [quant_01, quant_025, quant_05, quant_075, quant_10]\n",
    "    closest_idx = (np.abs(tmp_lst - lower_fences[lab_val_id])).argmin()\n",
    "    k_dict_low[lab_val_id] = round(tmp_lst[closest_idx], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9940738e-2c6d-4527-95b3-ac975194061f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# winsorize each column\n",
    "for lab_val_id in lab_value_item_ids:\n",
    "    lab_events_df.loc[\n",
    "        (lab_events_df[\"ITEMID\"].eq(lab_val_id))\n",
    "        & (lab_events_df[\"VALUENUM\"] > k_dict_up[lab_val_id]),\n",
    "        \"VALUENUM\",\n",
    "    ] = k_dict_up[lab_val_id]\n",
    "    # could be negative (Base Excess)\n",
    "    if lab_val_id != 5211:\n",
    "        lab_events_df.loc[\n",
    "            (lab_events_df[\"ITEMID\"].eq(lab_val_id))\n",
    "            & (lab_events_df[\"VALUENUM\"] < k_dict_low[lab_val_id])\n",
    "            & (lab_events_df[\"VALUENUM\"] != np.nan),\n",
    "            \"VALUENUM\",\n",
    "        ] = (\n",
    "            k_dict_low[lab_val_id] if k_dict_low[lab_val_id] > 0 else 0\n",
    "        )\n",
    "    else:\n",
    "        lab_events_df.loc[\n",
    "            (lab_events_df[\"ITEMID\"].eq(lab_val_id))\n",
    "            & (lab_events_df[\"VALUENUM\"] < k_dict_low[lab_val_id])\n",
    "            & (lab_events_df[\"VALUENUM\"] != np.nan),\n",
    "            \"VALUENUM\",\n",
    "        ] = k_dict_low[lab_val_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29b9992-36fb-49f8-93a8-df7bdfc26a89",
   "metadata": {},
   "source": [
    "## Labevents\n",
    "Add most common blood values as well. To reduce influence of missing data and the different blood values measured different times, we will use the following strategy:\n",
    "\n",
    "* Get the most common blood values across all HADM IDs (threshold should be ideally above 80-90% all values included in the inital anaylsis are measured at least once during the specific hospital stay). Filter all values, that are clinically relevant across a large population of ICU patients. This includes renal, liver and BGA parameters.\n",
    "\n",
    "* Include the max, min and average measurement for each such value + a flag, that indicates whether a value is in the normal range of values or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd4f189a-f1d3-449f-8039-33904aa62855",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item_id in list(id_to_name.keys()):\n",
    "    lab_name = id_to_name[item_id]\n",
    "    kwargs_dict = {\n",
    "        f\"{lab_name}_min\": (\"VALUENUM\", np.min),\n",
    "        f\"{lab_name}_max\": (\"VALUENUM\", np.max),\n",
    "        f\"{lab_name}_avg\": (\"VALUENUM\", np.nanmean),\n",
    "    }\n",
    "    lab_events_df_temp = lab_events_df[lab_events_df[\"ITEMID\"] == item_id]\n",
    "    max_lab_value_per_hadm = lab_events_df_temp.groupby(\"HADM_ID\").agg(**kwargs_dict)\n",
    "    # todo check why this reduces size of dataframe (removes rows and columns)\n",
    "    # icu_stay_df = pd.merge(icu_stay_df, max_lab_value_per_hadm, on=\"HADM_ID\")\n",
    "    for col in kwargs_dict.keys():\n",
    "        hadm_id_to_col = {\n",
    "            hadm_id: col\n",
    "            for hadm_id, col in zip(\n",
    "                max_lab_value_per_hadm.index, max_lab_value_per_hadm[col]\n",
    "            )\n",
    "        }\n",
    "        icu_stay_df[col] = icu_stay_df[\"HADM_ID\"].map(hadm_id_to_col)\n",
    "        # round avg column: 10,12345 -> 10,12\n",
    "        if col.endswith(\"_avg\"):\n",
    "            icu_stay_df[col] = icu_stay_df[col].round(2)\n",
    "    # flag to indicate whether a lab value has been measured or not\n",
    "    # this works, because whenever a value has no minimum (or maximum or avg) in this row, it has not been measured at all\n",
    "    # icu_stay_df[f'{lab_name}_measured'] = np.where(icu_stay_df[f'{lab_name}_min'] == , 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3702106-489d-47c1-a8c5-84c4942dbdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "icu_stay_df.to_csv(\"./temp_pp_data_files/data_02_2023_NEW_1.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
